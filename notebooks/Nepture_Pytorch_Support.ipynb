{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuTBdryPgyBQ2vez2zX1xX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hackathorn/WILS-MNIST/blob/main/notebooks/Nepture_Pytorch_Support.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall neptune-client\n",
        "!pip install neptune"
      ],
      "metadata": {
        "id": "ashvIyle2-qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ecD4zvkTypFb"
      },
      "outputs": [],
      "source": [
        "import neptune\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from neptune.types import File\n",
        "from neptune.utils import stringify_unsupported\n",
        "from torchvision import datasets, transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Initialize Neptune and create new Neptune run\n",
        "run = neptune.init_run(\n",
        "    project=\"hack-richard/WILS-MNIST-Neptune-Pytorch-Support\",\n",
        "    tags=\"Using MNIST\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vbmV3LXVpLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9uZXctdWkubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMjAxNTIyOC01NWJmLTRmYmYtYmUzMC1mZTFlMWE1MGVhODgifQ==\",\n",
        "    source_files=[\"*.py\"],\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysZRTTxX1hUx",
        "outputId": "89ad0d49-6832-4167-b675-4a8755d6a883"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f02ccd2dd318>:2: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
            "  run = neptune.init_run(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://new-ui.neptune.ai/hack-richard/WILS-MNIST-Neptune-Pytorch-Support/e/WILS-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"lr\": 1e-2,\n",
        "    \"batch_size\": 128,\n",
        "    \"input_sz\": 28 * 28 * 1,        # 32 * 32 * 3, \n",
        "    \"n_classes\": 10,\n",
        "    \"model_filename\": \"basemodel\",\n",
        "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "}\n"
      ],
      "metadata": {
        "id": "qV2Jwr8k1mSR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model & Dataset\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(input_sz, hidden_dim * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = input.view(-1, 28*28*1)\n",
        "        # x = input.view(-1, 32 * 32 * 3)\n",
        "        return self.main(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "--8vgh1s1pSg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use MNIST instead of CIFAR10\n",
        "\n",
        "Derived from https://gist.github.com/xmfbit/b27cdbff68870418bdb8cefa86a2d558"
      ],
      "metadata": {
        "id": "KhVyVoMXJA_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data/MNIST'\n",
        "# if not os.path.exists(root):\n",
        "#     os.mkdir(root)\n",
        "\n",
        "data_tfms = transforms.Compose([transforms.ToTensor(), \n",
        "                            transforms.Normalize((0.5,), (1.0,))],\n",
        "                           )\n",
        "# if not exist, download mnist dataset\n",
        "train_set = datasets.MNIST(data_dir, train=True, transform=data_tfms, download=True)\n",
        "test_set = datasets.MNIST(data_dir, train=False, transform=data_tfms, download=True)\n",
        "combine_set = torch.utils.data.ConcatDataset([train_set, test_set])\n",
        "\n",
        "batch_size = 1      # was 100\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=train_set,\n",
        "                 batch_size=batch_size,\n",
        "                 shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                dataset=test_set,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False)\n",
        "combine_loader = torch.utils.data.DataLoader(\n",
        "                dataset=combine_set,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True)\n",
        "\n",
        "dataset_size = {\"train\": len(train_set), \n",
        "                \"test\": len(test_set),\n",
        "                \"combine\": len(combine_set),\n",
        "                }"
      ],
      "metadata": {
        "id": "JwnB7cAZIwxB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load CIFAR10 dataset"
      ],
      "metadata": {
        "id": "AKcFCgsNKz5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Experiment Config\n",
        "# data_dir = \"data/CIFAR10\"\n",
        "# compressed_ds = \"./data/CIFAR10/cifar-10-python.tar.gz\"\n",
        "# data_tfms = {\n",
        "#     \"train\": transforms.Compose(\n",
        "#         [\n",
        "#             transforms.RandomHorizontalFlip(),\n",
        "#             transforms.ToTensor(),\n",
        "#             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "#         ]\n",
        "#     ),\n",
        "#     \"val\": transforms.Compose(\n",
        "#     [\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "#     ]\n",
        "#     ),\n",
        "# }\n"
      ],
      "metadata": {
        "id": "Qv_4LzbO1j7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset = datasets.CIFAR10(data_dir, transform=data_tfms[\"train\"], download=True)\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#     trainset, batch_size=params[\"batch_size\"], shuffle=True, num_workers=0\n",
        "# )\n",
        "# dataset_size = {\"train\": len(trainset)}\n",
        "\n",
        "# validset = datasets.CIFAR10(data_dir, train=False, transform=data_tfms[\"train\"], download=True)\n",
        "# valid_loader = torch.utils.data.DataLoader(validset, batch_size=params[\"batch_size\"])\n",
        "# dataset_size = {\"train\": len(trainset), \"val\": len(validset)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evYR8Mbq1td4",
        "outputId": "ed48e463-b443-44c8-b7cf-a197c787b59d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instatiate model, criterion and optimizer\n",
        "model = BaseModel(params[\"input_sz\"], params[\"input_sz\"], params[\"n_classes\"]).to(params[\"device\"])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=params[\"lr\"])\n"
      ],
      "metadata": {
        "id": "arxSkqW61wC4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [0,1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "# classes = [\n",
        "#     \"airplane\",\n",
        "#     \"automobile\",\n",
        "#     \"bird\",\n",
        "#     \"cat\",\n",
        "#     \"deer\",\n",
        "#     \"dog\",\n",
        "#     \"frog\",\n",
        "#     \"horse\",\n",
        "#     \"ship\",\n",
        "#     \"truck\",\n",
        "# ]"
      ],
      "metadata": {
        "id": "DEWFA9QSQxy4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Log config & pararameters\n",
        "run[\"config/dataset/path\"] = data_dir\n",
        "run[\"config/dataset/transforms\"] = stringify_unsupported(data_tfms)\n",
        "run[\"config/dataset/size\"] = dataset_size\n",
        "run[\"config/model\"] = type(model).__name__\n",
        "run[\"config/criterion\"] = type(criterion).__name__\n",
        "run[\"config/optimizer\"] = type(optimizer).__name__\n",
        "run[\"config/hyperparameters\"] = stringify_unsupported(params)\n",
        "run[\"config/classes\"] = stringify_unsupported(classes)\n"
      ],
      "metadata": {
        "id": "xCSt80eD1y4g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Log losses and metrics\n",
        "for i, (x, y) in enumerate(train_loader, 0):\n",
        "    x, y = x.to(params[\"device\"]), y.to(params[\"device\"])\n",
        "    optimizer.zero_grad()\n",
        "    # outputs = model.forward(x, params[\"input_sz\"])\n",
        "    outputs = model.forward(x)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    loss = criterion(outputs, y)\n",
        "    acc = (torch.sum(preds == y.data)) / len(x)\n",
        "\n",
        "    # Log batch loss\n",
        "    run[\"training/batch/loss\"].append(loss)\n",
        "\n",
        "    # Log batch accuracy\n",
        "    run[\"training/batch/acc\"].append(acc)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "iCpZv5PV12JA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# More options\n"
      ],
      "metadata": {
        "id": "kQIJ4wNoDWRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Saving model\n",
        "fname = params[\"model_filename\"]\n",
        "\n",
        "# Saving model architecture to .txt\n",
        "with open(f\"./{fname}_arch.txt\", \"w\") as f:\n",
        "    f.write(str(model))\n",
        "# Saving model weights .pth\n",
        "torch.save(model.state_dict(), f\"./{fname}.pth\")    #TODO where is this save\n",
        "\n"
      ],
      "metadata": {
        "id": "16lMSDT6DY0Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.1: Log model archictecture & weights\n",
        "run[f\"io_files/artifacts/{params['model_filename']}_arch\"].upload(\n",
        "    f\"./{params['model_filename']}_arch.txt\"\n",
        ")\n",
        "run[f\"io_files/artifacts/{params['model_filename']}\"].upload(f\"./{params['model_filename']}.pth\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YXMM4gsrDb1R"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Log Torch Tensors as images with predictions\n",
        "\n",
        "# Getting batch\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "model.eval()\n",
        "\n",
        "# Moving model to cpu for inference\n",
        "if torch.cuda.is_available():\n",
        "    model.to(\"cpu\")\n",
        "\n",
        "# Predict batch of n_samples\n",
        "n_samples = 50\n",
        "imgs = images[:n_samples]\n",
        "probs = F.softmax(model(imgs), dim=1)\n",
        "\n",
        "# Decode probs and Log tensors as image\n",
        "for i, ps in enumerate(probs):\n",
        "    pred = classes[torch.argmax(ps)]\n",
        "    ground_truth = classes[labels[i]]\n",
        "    description = \"\\n\".join(\n",
        "        [f\"class {classes[n]}: {np.round(p.detach().numpy() * 100, 2)}%\" for n, p in enumerate(ps)]\n",
        "    )\n",
        "\n",
        "    # Log Series of Tensors as Image and Predictions.\n",
        "    run[\"images/predictions\"].append(\n",
        "        File.as_image(imgs[i].squeeze().permute(2, 1, 0).clip(0, 1)),\n",
        "        name=f\"{i}_{pred}_{ground_truth}\",\n",
        "        description=description,\n",
        "    )"
      ],
      "metadata": {
        "id": "IlWClzRlDdmS"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}